{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5501999ad89540f516dca9240a01970e",
     "grade": false,
     "grade_id": "cell-100899e0deea9789",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Tutorial 26: Data files and I/O\n",
    "\n",
    "## PHYS 2600, Spring 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "492a064bb8a6086a3ceb60c2da9aa12b",
     "grade": false,
     "grade_id": "cell-e4302376dbe2ef21",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Import cell\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5f62016c4d47207aa3440e321ecfed2",
     "grade": false,
     "grade_id": "cell-a7962c4e129aca38",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## T26.1 - Basic I/O and the CSV format\n",
    "\n",
    "Let's start with some basic file parsing.\n",
    "\n",
    "### Part A\n",
    "\n",
    "To begin with, I've provided a comma-separated value file called `example_data_tut25.csv`.  CSV files are tabular data, with the rows separated by newlines and the columns within each row separated by commas.\n",
    "\n",
    "Since a CSV file is human-readable, a good place to start is to __open the file and look at its contents.__  You should see how many rows and columns to expect.  You'll also notice that this particular file contains a __header__: the very first line of the file doesn't contain data, but instead a set of strings that describe the data columns below.  (Data which exists to tell us generic information about other data like this is usually called __metadata__.)\n",
    "\n",
    "The cell below contains an example line of data from this CSV file, formatted as a string.  To get the numbers out as a list, you should carry out the following steps:\n",
    "\n",
    "1. Use the `.strip()` string method to get rid of the newline character `\\n`.\n",
    "2. Use the `.split()` string method to divide the string into smaller strings.\n",
    "3. Convert each string in the list to a floating-point number using the `float()` type-casting function.  (You'll need a `for` loop to run through the list.)\n",
    "\n",
    "__Implement the function `parse_line_csv` below__ to carry out these three steps, then run the cell below to run it on `sample_line` and check that you parsed it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "760c3fad543e196fdcffc53ae9b01018",
     "grade": true,
     "grade_id": "cell-92bdb8a08bb8bb51",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "sample_line = '1,3.31,-0.27,7.79\\n'\n",
    "\n",
    "def parse_line_csv(line):\n",
    "    ### BEGIN SOLUTION\n",
    "    strip_line = line.strip()\n",
    "    line_list = strip_line.split(',')\n",
    "    number_list = []\n",
    "    for x in line_list:\n",
    "        number_list.append(float(x))\n",
    "        \n",
    "    return number_list\n",
    "    ### END SOLUTION\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7ce1ac70fcd15c14b52b8ddb6b1dd8e",
     "grade": true,
     "grade_id": "cell-6a9acf2904c19bd2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 3.31, -0.27, 7.79]\n"
     ]
    }
   ],
   "source": [
    "parsed_line = parse_line_csv(sample_line)\n",
    "print(parsed_line)\n",
    "\n",
    "import numpy.testing as npt\n",
    "npt.assert_allclose(parsed_line, [1.0, 3.31, -0.27, 7.79])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c788a562a140847922ab73eea1c7890",
     "grade": false,
     "grade_id": "cell-c3977ae033786f17",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Part B\n",
    "\n",
    "Now you're ready to process the whole data file!  In the cell below, use the `with open(...) as ...` syntax to open the file `example_data_tut26.csv`, and then use `readline()` or `readlines()` and your function from part A to create a two-dimensional NumPy array containing the data.  __Save it to a variable called `proc_data`.__\n",
    "\n",
    "_(Hint: don't forget the header line!  Since it contains metadata and not data, you should store that to a different variable or discard it entirely.)_\n",
    "\n",
    "_(Another hint: it's easiest to make a list of lists, and then use `np.array()` to typecast at the end.  You could also allocate an array of zeroes and then fill it in, line by line, but that requires knowing the exact dimensions of the data before you start by looking at the file - not always practical!)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a922673872a0787eee9035ae4dd8ec1b",
     "grade": false,
     "grade_id": "cell-b1054b9918bbc8be",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial,x,y,t\n",
      "\n",
      "[[ 1.    3.31 -0.27  7.79]\n",
      " [ 2.    0.41 -0.91  4.22]\n",
      " [ 3.   -2.35 -0.54  9.24]\n",
      " [ 4.   -1.62 -1.52 10.35]\n",
      " [ 5.   -0.98 -4.51 15.99]\n",
      " [ 6.   -3.86  3.76  7.4 ]\n",
      " [ 7.    4.67 -3.84 10.65]\n",
      " [ 8.    4.36 -0.61 16.65]\n",
      " [ 9.   -1.29  2.53 13.74]\n",
      " [10.   -4.63  3.13  7.47]\n",
      " [11.    0.46  4.39  0.68]\n",
      " [12.   -0.43  2.67  2.86]]\n"
     ]
    }
   ],
   "source": [
    "data_filename = 'example_data_tut26.csv'\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "with open(data_filename) as dfile:\n",
    "    header = dfile.readline()\n",
    "    raw_lines = dfile.readlines()\n",
    "\n",
    "proc_data = []\n",
    "for line in raw_lines:\n",
    "    proc_data.append(parse_line_csv(line))\n",
    "    \n",
    "proc_data = np.array(proc_data)\n",
    "\n",
    "print(header)\n",
    "print(proc_data)\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7030374752f63e687573c3fc5223588",
     "grade": true,
     "grade_id": "cell-1961b4fdef4cd111",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.    3.31 -0.27  7.79]\n",
      " [ 2.    0.41 -0.91  4.22]\n",
      " [ 3.   -2.35 -0.54  9.24]\n",
      " [ 4.   -1.62 -1.52 10.35]\n",
      " [ 5.   -0.98 -4.51 15.99]\n",
      " [ 6.   -3.86  3.76  7.4 ]\n",
      " [ 7.    4.67 -3.84 10.65]\n",
      " [ 8.    4.36 -0.61 16.65]\n",
      " [ 9.   -1.29  2.53 13.74]\n",
      " [10.   -4.63  3.13  7.47]\n",
      " [11.    0.46  4.39  0.68]\n",
      " [12.   -0.43  2.67  2.86]]\n",
      "(12, 4)\n"
     ]
    }
   ],
   "source": [
    "print(proc_data)\n",
    "print(proc_data.shape)\n",
    "\n",
    "import numpy.testing as npt\n",
    "npt.assert_allclose(proc_data[9], [10, -4.63, 3.13, 7.47])\n",
    "assert proc_data.shape == (12,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c62ccf6f5dde7235a4e954f86881de25",
     "grade": false,
     "grade_id": "cell-edf5bd56254c036e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Part C\n",
    "\n",
    "Now our data is ready to use!  Let's apply a transformation, say we want to convert the middle two columns (x,y) to a single distance $d = \\sqrt{x^2 + y^2}$.  That's easy enough to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3747e0cc7db201e1f48ec8d07199daa0",
     "grade": false,
     "grade_id": "cell-64072e9be23600bf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          3.32099383]\n",
      " [ 2.          0.99809819]\n",
      " [ 3.          2.41124449]\n",
      " [ 4.          2.22144097]\n",
      " [ 5.          4.61524647]\n",
      " [ 6.          5.38861763]\n",
      " [ 7.          6.04603176]\n",
      " [ 8.          4.40246522]\n",
      " [ 9.          2.83989436]\n",
      " [10.          5.58872078]\n",
      " [11.          4.41403444]\n",
      " [12.          2.70440382]]\n"
     ]
    }
   ],
   "source": [
    "distance_data = np.zeros((12,2))\n",
    "distance_data[:,0] = proc_data[:,0]\n",
    "distance_data[:,1] = np.sqrt(proc_data[:,1]**2 + proc_data[:,2]**2)\n",
    "\n",
    "print(distance_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "746cd7e3104870d7b91d4fc6c12b67e8",
     "grade": false,
     "grade_id": "cell-6e00367022b023a9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now we'd like to __write the transformed data out__ to a new file called `distances.csv`.  Use the `with open(..., 'w') as ...` context syntax to open `distances.csv` for writing, and then use the `.write()` file method to write lines to the file.  \n",
    "\n",
    "__Use string formatting with the `g` format code__ for both numbers, and don't forget to include the newline `\\n` at the end of every line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4ffd6f3897150ecdb0334a63b4cddff",
     "grade": false,
     "grade_id": "cell-e565d219d9093cc5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "### BEGIN SOLUTION\n",
    "with open('distances.csv', 'w') as dist_file:\n",
    "    for row in distance_data:\n",
    "        dist_file.write('%g,%g\\n' % (row[0], row[1]))\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59de885d8ef35fe64425f68a432e0628",
     "grade": true,
     "grade_id": "cell-266bc7249fd9c8c9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1,3.32099\\n', '2,0.998098\\n', '3,2.41124\\n', '4,2.22144\\n', '5,4.61525\\n', '6,5.38862\\n', '7,6.04603\\n', '8,4.40247\\n', '9,2.83989\\n', '10,5.58872\\n', '11,4.41403\\n', '12,2.7044\\n']\n"
     ]
    }
   ],
   "source": [
    "with open('distances.csv', 'r') as dist_file:\n",
    "    dlines = dist_file.readlines()\n",
    "\n",
    "print(dlines)\n",
    "assert len(dlines) == 12\n",
    "assert dlines[4] == '5,4.61525\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "023c22e571bcd785f056aac1c81fad1e",
     "grade": false,
     "grade_id": "cell-653133e7666e16d4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## T26.2 - Data mining the weather\n",
    "\n",
    "Let's try working with some real data!  The provided file `weather_data_boulder_0918.csv` contains [NOAA weather data](https://www.ncdc.noaa.gov/cdo-web/) for various weather stations in the vicinity of Boulder, taken over 28 days in the month of September 2018.  The columns, in order, are:\n",
    "\n",
    "* Weather station ID\n",
    "* Weather station name\n",
    "* Date of observation\n",
    "* Precipitation total (inches)\n",
    "* Average temperature (degrees F)\n",
    "* Max temperature (degrees F)\n",
    "* Min temperature (degrees F)\n",
    "\n",
    "Since this is a real dataset, we'll encounter many real-world data wrangling problems: \"cleaning\" out extraneous data we don't care about, transforming and combining data, and so on.\n",
    "\n",
    "Once again, start by __opening up the raw data file and looking through it__ to get a sense for the raw data.  One line will look something like this:\n",
    "\n",
    "\"USS0005J42S\",\"NIWOT, CO US\",\"2018-09-14\",\"0.00\",\"57\",\"72\",\"41\"\n",
    "\n",
    "In fact, this line with all data filled in is _rare_: most of the stations reported seem to only measure precipitation, so their temperature columns are missing entirely.  Of the stations reporting temperatures, most only record max/min and not the average.  Real data is often messy!\n",
    "\n",
    "\n",
    "### Part A\n",
    "\n",
    "Notice that this file is especially challenging to parse: this is a variation on CSV where the data are contained in double quotes `\"\"` and _then_ separated by commas.  This is done so that commas can be used _inside_ the dataset, as in the station name above.\n",
    "\n",
    "As a warm-up, I've included a single line of the data file as a string below.  __Extract the precipitation, max temperature, and min temperature__ from this string as a 3-entry NumPy array.\n",
    "\n",
    "\n",
    "_(Hint: if you just pretend this is a regular CSV file and split on the commas, you'll end up breaking apart the station name field.  But if you only want the precipitation and temperature data, you can just ignore the name - but keep track of which column ends up where in the list after using `split`...)_\n",
    "\n",
    "_(Another hint: the double quotes `\"` will only get in your way here!  You can remove all the instances of a character from a string by using the `.replace()` method.  For example, `\"hello world\".replace('l', '')` will give you the string `'heo word'`.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2cde7622d20db20d89a933134599565a",
     "grade": false,
     "grade_id": "cell-0adf1e4a5b5a10de",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USS0005J42S', 'NIWOT', ' CO US', '2018-09-14', '0.00', '57', '72', '41']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wline = '\"USS0005J42S\",\"NIWOT, CO US\",\"2018-09-14\",\"0.00\",\"57\",\"72\",\"41\"\\n'\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "wline.strip().replace('\"', '').split(',')\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d273144b2142a15745af9e1322525ba6",
     "grade": false,
     "grade_id": "cell-5bccb3f17c01437a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Part B\n",
    "\n",
    "Now parse the whole data file, and __create a 2-D NumPy array containing the precipitation, max temperature, and min temperature__ for __only a single Boulder station, ID `USW00094075`.__  There are two ways you can do this:\n",
    "\n",
    "1. Pretend this is a regular CSV file, and parse it by splitting on the commas as you did for the single line in part A.\n",
    "2. Use the `csv` module [see the documentation here](https://docs.python.org/3/library/csv.html), and use a `csv.reader` to parse the dataset.  The `csv` module can recognize variations of CSV like this one and will deal with the quotes properly if you set the `quotechar` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c13ccc45fd3d14eeb08f82ddbf3f96f",
     "grade": false,
     "grade_id": "cell-2616ec7725948339",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0e+00 6.4e+01 3.5e+01]\n",
      " [0.0e+00 6.0e+01 4.0e+01]\n",
      " [0.0e+00 6.3e+01 4.0e+01]\n",
      " [2.7e-01 6.0e+01 3.9e+01]\n",
      " [6.0e-02 5.6e+01 3.4e+01]\n",
      " [4.0e-02 6.0e+01 3.0e+01]\n",
      " [6.0e-02 6.8e+01 3.3e+01]\n",
      " [0.0e+00 6.7e+01 3.8e+01]\n",
      " [0.0e+00 7.1e+01 3.6e+01]\n",
      " [0.0e+00 7.1e+01 3.9e+01]\n",
      " [0.0e+00 7.2e+01 4.6e+01]\n",
      " [0.0e+00 7.3e+01 4.3e+01]\n",
      " [0.0e+00 7.1e+01 4.2e+01]\n",
      " [0.0e+00 7.2e+01 4.2e+01]\n",
      " [0.0e+00 7.2e+01 4.7e+01]\n",
      " [0.0e+00 7.2e+01 4.7e+01]\n",
      " [0.0e+00 7.3e+01 4.2e+01]\n",
      " [7.0e-02 6.9e+01 4.4e+01]\n",
      " [0.0e+00 6.0e+01 3.1e+01]\n",
      " [0.0e+00 6.0e+01 2.6e+01]\n",
      " [0.0e+00 6.5e+01 3.7e+01]\n",
      " [0.0e+00 6.6e+01 4.1e+01]\n",
      " [1.9e-01 5.7e+01 3.8e+01]\n",
      " [0.0e+00 5.2e+01 2.5e+01]\n",
      " [0.0e+00 5.6e+01 2.6e+01]\n",
      " [0.0e+00 6.1e+01 3.5e+01]\n",
      " [0.0e+00 5.9e+01 3.5e+01]\n",
      " [0.0e+00 6.7e+01 4.3e+01]]\n"
     ]
    }
   ],
   "source": [
    "weather_filename = 'weather_data_boulder_0918.csv'\n",
    "boulder_data = []\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "# First method:\n",
    "with open(weather_filename, 'r') as weather_file:\n",
    "    for line in weather_file:\n",
    "        split_data = line.strip().replace('\"', '').split(',')\n",
    "        #print(split_data)\n",
    "        if split_data[0] == 'USW00094075':\n",
    "            boulder_data.append([split_data[4], split_data[6], split_data[7]])\n",
    "\n",
    "            \n",
    "boulder_data = np.array(boulder_data, np.float)\n",
    "\n",
    "# Second method:\n",
    "boulder_data = []\n",
    "with open(weather_filename, 'r') as weather_file:\n",
    "    reader = csv.reader(weather_file, delimiter=',', quotechar='\"')\n",
    "    for line in reader:\n",
    "        if line[0] == 'USW00094075':\n",
    "            boulder_data.append([line[3], line[5], line[6]])\n",
    "\n",
    "boulder_data = np.array(boulder_data, np.float)\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "print(boulder_data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4a6d718ff8d64bafac3c3f2b687af98",
     "grade": false,
     "grade_id": "cell-b0603f050d01101e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Part C\n",
    "\n",
    "Now extract the following quantities from your cleaned array of data in the cell below:\n",
    "\n",
    "* Total precipitation;\n",
    "* The lowest minimum temperature and highest maximum temperature;\n",
    "* The average temperatures (obtained by averaging min/max temperature) on every Tuesday.\n",
    "\n",
    "_(Hint: for the last one, use `np.mean()` and slicing to produce a 1d array containing the average temperature, then one more slice to cut the list down to the four Tuesdays only.  The data runs from 9/2 to 9/29, so the first day is a Sunday and the last is a Saturday.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cd4f8e2ecddf9eb3c3a1e9dc61a9e5f",
     "grade": false,
     "grade_id": "cell-23cc3adf1fc2b283",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69\n",
      "25.0\n",
      "73.0\n",
      "[49.5 50.  51.5 49.5 45.  45.  50.5 52.5 53.5 55.  59.  58.  56.5 57.\n",
      " 59.5 59.5 57.5 56.5 45.5 43.  51.  53.5 47.5 38.5 41.  48.  47.  55. ]\n",
      "[51.5 55.  57.5 38.5]\n",
      "[51.5 55.  57.5 38.5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### BEGIN SOLUTION\n",
    "total_precip = np.sum(boulder_data[:,0])\n",
    "print(total_precip)\n",
    "min_temp = np.min(boulder_data[:,2])\n",
    "print(min_temp)\n",
    "max_temp = np.max(boulder_data[:,1])\n",
    "print(max_temp)\n",
    "avg_temps = np.mean(boulder_data[:,1:], axis=1)\n",
    "print(avg_temps)\n",
    "\n",
    "# First day is Sunday, so the first Tuesday is index 2.\n",
    "# Skip by 7 after that using slice notation.\n",
    "# Or give the four Tuesday indices explicitly.\n",
    "print(avg_temps[2::7])\n",
    "print(avg_temps[[2,9,16,23]])\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7aae6c304b8dcc02efc0cf94f6442959",
     "grade": false,
     "grade_id": "cell-52ada97250412743",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Part D (optional challenge)\n",
    "\n",
    "Can you go back and report the lowest minimum and highest maximum temperature across _all weather stations_ in the file?  (This is tricky because many of the stations don't report any temperatures at all!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0b1ff2a94d2efb537fd65e6caf1e228",
     "grade": false,
     "grade_id": "cell-a52e8c19bfe55db3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244, 2)\n",
      "25.0\n",
      "96.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### BEGIN SOLUTION\n",
    "temp_data = []\n",
    "with open(weather_filename, 'r') as weather_file:\n",
    "    weather_file.readline() # Discard header\n",
    "    reader = csv.reader(weather_file, delimiter=',', quotechar='\"')\n",
    "    \n",
    "    for line in reader:\n",
    "        if line[5] != '' and line[6] != '':\n",
    "            temp_data.append([line[5], line[6]])\n",
    "\n",
    "temp_data = np.array(temp_data, np.float)\n",
    "print(temp_data.shape)\n",
    "\n",
    "print(np.min(temp_data[:,1]))\n",
    "print(np.max(temp_data[:,0]))\n",
    "### END SOLUTION\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
